"""MCP Server for Kakao PlayMCP integration using official MCP SDK FastMCP"""

import os
import uuid
import base64
import json
from pathlib import Path
from typing import Optional
import httpx

from mcp.server.fastmcp import FastMCP

from app.core.config import settings
from app.utils.audio import get_audio_duration_ms
from app.services.stt_service_async import AsyncSTTService
from app.services.analysis_service import analysis_service


# Create MCP server instance using official SDK's FastMCP
mcp = FastMCP(
    name="CallMate í†µí™”ë¶„ì„",
    instructions="""ì˜ì—…/ìƒë‹´ í†µí™”ë¥¼ AIë¡œ ë¶„ì„í•˜ê³  ìµœì ì˜ ì‘ëŒ€ ë°©ë²•ì„ ì¶”ì²œí•˜ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

ğŸŒ í™ˆí˜ì´ì§€: https://callmate-fe.vercel.app/

[ë¶„ì„ ê¸°ëŠ¥]
â€¢ ìŒì„±â†’í…ìŠ¤íŠ¸ ì „ì‚¬ (í™”ì ë¶„ë¦¬ í¬í•¨)
â€¢ ê³ ê° ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ê±±ì •/í™”ë‚¨ ë“±)
â€¢ ê³ ê° ìƒíƒœ íŒŒì•… (ê´€ì‹¬ìˆìŒ, ê³ ë¯¼ì¤‘, ë§ì„¤ì„, êµ¬ë§¤ì¤€ë¹„ë¨, ë¶ˆë§Œì¡± ë“±)

[ìš”ì•½ ê¸°ëŠ¥]
â€¢ ëŒ€í™” í•µì‹¬ ìš”ì•½ (ì£¼ìš” ì£¼ì œ, ì§ˆë¬¸, ë‹µë³€)
â€¢ ê³ ê° ë‹ˆì¦ˆ ë¶„ì„ (ì „í™” ì‚¬ìœ , ìš”êµ¬ì‚¬í•­, ê³ ë¯¼ê±°ë¦¬)
â€¢ ëŒ€í™” íë¦„ ë° ì „í™˜ì  íŒŒì•…

[ì¶”ì²œ ê¸°ëŠ¥]
â€¢ ìƒë‹´ ìœ í˜•ë³„ ë§ì¶¤ ì‘ëŒ€ ë©˜íŠ¸ 3ê°€ì§€ ì œê³µ
  - íŒë§¤/ì„¤ë“: ì†ì‹¤ ê°•ì¡°, ëŒ€ì•ˆ ì œì‹œ, ë§ˆë¬´ë¦¬ ë©˜íŠ¸
  - ì•ˆë‚´/ì •ë³´: í•µì‹¬ í¬ì¸íŠ¸, ì¶”ê°€ ì•ˆë‚´, ë§ˆë¬´ë¦¬ ë©˜íŠ¸
  - ë¶ˆë§Œ/ë¬¸ì œ: ê³µê° í‘œí˜„, í•´ê²° ë°©ì•ˆ, ë§ˆë¬´ë¦¬ ë©˜íŠ¸
â€¢ ë‹¤ìŒ ì•¡ì…˜ ì œì•ˆ (ì¶”ê°€ ìƒë‹´ ì˜ˆì •, ê²¬ì  ë°œì†¡ ë“±)""",
    stateless_http=True  # Required for Streamable HTTP
)


def _prepare_analysis_data_from_dict(utterances: list, speakers: list, my_speaker: Optional[str] = None):
    """ì „ì‚¬ ê²°ê³¼ dictì—ì„œ ë¶„ì„ ë°ì´í„° ì „ì²˜ë¦¬"""
    conversation_formatted = "\n".join(
        f"{u['speaker']}: {u['text']}" for u in utterances
    )

    speaker_segments = []
    for speaker in speakers:
        speaker_utterances = [u for u in utterances if u["speaker"] == speaker]
        full_text = " ".join(u["text"] for u in speaker_utterances)
        speaker_segments.append({
            "speaker": speaker,
            "full_text": full_text,
            "utterances": speaker_utterances
        })

    if my_speaker and my_speaker in speakers:
        agent_speaker = my_speaker
        other_speakers = [s for s in speakers if s != agent_speaker]
    else:
        customer_speaker = analysis_service._detect_customer_speaker(
            speaker_segments, utterances
        )
        agent_speaker = [s for s in speakers if s != customer_speaker][0] if len(speakers) > 1 else speakers[0]
        other_speakers = [s for s in speakers if s != agent_speaker]

    other_text = ""
    for seg in speaker_segments:
        if seg["speaker"] in other_speakers:
            other_text += seg["full_text"] + " "

    agent_text = ""
    for seg in speaker_segments:
        if seg["speaker"] == agent_speaker:
            agent_text = seg["full_text"]
            break

    return {
        "utterances": utterances,
        "speaker_segments": speaker_segments,
        "conversation_formatted": conversation_formatted,
        "agent_speaker": agent_speaker,
        "other_speakers": other_speakers,
        "agent_text": agent_text,
        "other_text": other_text.strip()
    }


@mcp.tool(
    name="analyze_call",
    description="""ìŒì„± íŒŒì¼(base64)ì„ ë¶„ì„í•˜ì—¬ í†µí™” ë‚´ìš©ì„ ì „ì‚¬í•˜ê³  AIë¡œ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤.

ì…ë ¥:
- audio_base64: ìŒì„± íŒŒì¼ì˜ base64 ì¸ì½”ë”© ë¬¸ìì—´ (mp3, wav, m4a ì§€ì›)
- filename: íŒŒì¼ëª… (í™•ì¥ì í¬í•¨, ì˜ˆ: "call.mp3")
- my_speaker: (ì„ íƒ) ë³¸ì¸ í™”ì (A ë˜ëŠ” B) - ë¯¸ì§€ì • ì‹œ ìë™ ê°ì§€
- consultation_type: ìƒë‹´ ìœ í˜• (sales/information/complaint), ê¸°ë³¸ê°’: sales

ì¶œë ¥:
- transcript: ì „ì‚¬ ê²°ê³¼ (full_text, utterances, speakers)
- analysis: ì¢…í•© ë¶„ì„ ê²°ê³¼ (ê°ì •, ê³ ê° ìƒíƒœ, ìš”ì•½, ì¶”ì²œ ë©˜íŠ¸ ë“±)"""
)
async def analyze_call(
    audio_base64: str,
    filename: str = "audio.mp3",
    my_speaker: Optional[str] = None,
    consultation_type: str = "sales"
) -> dict:
    """ìŒì„± íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì „ì‚¬ ë° ì¢…í•© ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    allowed_extensions = {".mp3", ".wav", ".m4a"}
    file_ext = Path(filename).suffix.lower()
    if file_ext not in allowed_extensions:
        return {"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (mp3, wav, m4aë§Œ ê°€ëŠ¥)"}

    # Base64 ë””ì½”ë”©
    try:
        file_content = base64.b64decode(audio_base64)
    except Exception:
        return {"error": "ì˜ëª»ëœ base64 ë°ì´í„°ì…ë‹ˆë‹¤."}

    # íŒŒì¼ ì €ì¥
    upload_dir = Path(settings.UPLOAD_DIR)
    upload_dir.mkdir(parents=True, exist_ok=True)

    file_id = str(uuid.uuid4())
    file_path = upload_dir / f"{file_id}{file_ext}"

    try:
        with open(file_path, "wb") as f:
            f.write(file_content)

        # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ (ìµœëŒ€ 30ë¶„)
        duration_ms = get_audio_duration_ms(str(file_path))
        max_duration_ms = 30 * 60 * 1000
        if duration_ms > max_duration_ms:
            os.remove(file_path)
            return {"error": "ìŒì„± íŒŒì¼ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. (ìµœëŒ€ 30ë¶„)"}

        # 1. ì „ì‚¬ (STT)
        stt_service = AsyncSTTService()
        transcript_result = await stt_service.transcribe_with_progress(
            audio_file_path=str(file_path),
            language_code="ko"
        )

        # 2. ë¶„ì„ ë°ì´í„° ì¤€ë¹„
        data = _prepare_analysis_data_from_dict(
            utterances=transcript_result["utterances"],
            speakers=transcript_result["speakers"],
            my_speaker=my_speaker
        )

        # 3. ì¢…í•© ë¶„ì„
        analysis = await analysis_service.analyze_call(
            transcript_id=file_id,
            conversation_formatted=data["conversation_formatted"],
            speaker_segments=data["speaker_segments"],
            utterances=data["utterances"],
            agent_speaker=data["agent_speaker"],
            other_speakers=data["other_speakers"],
            script_context=None
        )

        # íŒŒì¼ ì‚­ì œ
        if file_path.exists():
            os.remove(file_path)

        return {
            "transcript": {
                "file_id": file_id,
                "duration_ms": transcript_result["duration"],
                "full_text": transcript_result["full_text"],
                "utterances": transcript_result["utterances"],
                "speakers": transcript_result["speakers"]
            },
            "analysis": analysis
        }

    except Exception as e:
        if file_path.exists():
            os.remove(file_path)
        return {"error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}


@mcp.tool(
    name="analyze_call_from_url",
    description="""ê³µê°œ URLì˜ ìŒì„± íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
- analyze_call_from_url("https://callmate-uploads.s3.ap-northeast-2.amazonaws.com/samples/sample1.mp3")

ì…ë ¥:
- audio_url: ìŒì„± íŒŒì¼ì˜ ê³µê°œ URL (mp3, wav, m4a ì§€ì›)
- my_speaker: (ì„ íƒ) ë³¸ì¸ í™”ì (A ë˜ëŠ” B) - ë¯¸ì§€ì • ì‹œ ìë™ ê°ì§€
- consultation_type: ìƒë‹´ ìœ í˜• (sales/information/complaint), ê¸°ë³¸ê°’: sales

ì¶œë ¥:
- transcript: ì „ì‚¬ ê²°ê³¼ (full_text, utterances, speakers)
- analysis: ì¢…í•© ë¶„ì„ ê²°ê³¼ (ê°ì •, ê³ ê° ìƒíƒœ, ìš”ì•½, ì¶”ì²œ ë©˜íŠ¸ ë“±)"""
)
async def analyze_call_from_url(
    audio_url: str,
    my_speaker: Optional[str] = None,
    consultation_type: str = "sales"
) -> dict:
    """URLì—ì„œ ìŒì„± íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤."""

    # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
    try:
        filename = audio_url.split("/")[-1].split("?")[0]
        if not filename:
            filename = "audio.mp3"
    except:
        filename = "audio.mp3"

    file_ext = Path(filename).suffix.lower()
    allowed_extensions = {".mp3", ".wav", ".m4a"}
    if file_ext not in allowed_extensions:
        return {"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (mp3, wav, m4aë§Œ ê°€ëŠ¥)"}

    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    upload_dir = Path(settings.UPLOAD_DIR)
    upload_dir.mkdir(parents=True, exist_ok=True)

    file_id = str(uuid.uuid4())
    file_path = upload_dir / f"{file_id}{file_ext}"

    try:
        # httpxë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.get(audio_url)
            response.raise_for_status()
            file_content = response.content

        with open(file_path, "wb") as f:
            f.write(file_content)

        # ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ (ìµœëŒ€ 30ë¶„)
        duration_ms = get_audio_duration_ms(str(file_path))
        max_duration_ms = 30 * 60 * 1000
        if duration_ms > max_duration_ms:
            os.remove(file_path)
            return {"error": "ìŒì„± íŒŒì¼ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. (ìµœëŒ€ 30ë¶„)"}

        # 1. ì „ì‚¬ (STT)
        stt_service = AsyncSTTService()
        transcript_result = await stt_service.transcribe_with_progress(
            audio_file_path=str(file_path),
            language_code="ko"
        )

        # 2. ë¶„ì„ ë°ì´í„° ì¤€ë¹„
        data = _prepare_analysis_data_from_dict(
            utterances=transcript_result["utterances"],
            speakers=transcript_result["speakers"],
            my_speaker=my_speaker
        )

        # 3. ì¢…í•© ë¶„ì„
        analysis = await analysis_service.analyze_call(
            transcript_id=file_id,
            conversation_formatted=data["conversation_formatted"],
            speaker_segments=data["speaker_segments"],
            utterances=data["utterances"],
            agent_speaker=data["agent_speaker"],
            other_speakers=data["other_speakers"],
            script_context=None
        )

        # íŒŒì¼ ì‚­ì œ
        if file_path.exists():
            os.remove(file_path)

        return {
            "transcript": {
                "file_id": file_id,
                "duration_ms": transcript_result["duration"],
                "full_text": transcript_result["full_text"],
                "utterances": transcript_result["utterances"],
                "speakers": transcript_result["speakers"]
            },
            "analysis": analysis
        }

    except httpx.HTTPError as e:
        if file_path.exists():
            os.remove(file_path)
        return {"error": f"URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"}
    except Exception as e:
        if file_path.exists():
            os.remove(file_path)
        return {"error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}


@mcp.tool(
    name="analyze_sample_call",
    description="""ìƒ˜í”Œ í†µí™” ë…¹ìŒì„ ë¶„ì„í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¯¸ë¦¬ ì¤€ë¹„ëœ ìƒ˜í”Œ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
- analyze_sample_call("sample1") - ì˜ì—… í†µí™” ìƒ˜í”Œ
- analyze_sample_call("sample2") - ê³ ê° ìƒë‹´ ìƒ˜í”Œ

ì…ë ¥:
- sample_id: ìƒ˜í”Œ íŒŒì¼ ID (sample1, sample2 ë“±)
- my_speaker: (ì„ íƒ) ë³¸ì¸ í™”ì (A ë˜ëŠ” B) - ë¯¸ì§€ì • ì‹œ ìë™ ê°ì§€
- consultation_type: ìƒë‹´ ìœ í˜• (sales/information/complaint), ê¸°ë³¸ê°’: sales

ì¶œë ¥:
- transcript: ì „ì‚¬ ê²°ê³¼
- analysis: ì¢…í•© ë¶„ì„ ê²°ê³¼"""
)
async def analyze_sample_call(
    sample_id: str = "sample1",
    my_speaker: Optional[str] = None,
    consultation_type: str = "sales"
) -> dict:
    """ìƒ˜í”Œ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤."""

    # S3 ìƒ˜í”Œ URL ìƒì„±
    sample_url = f"https://callmate-uploads.s3.ap-northeast-2.amazonaws.com/samples/{sample_id}.mp3"

    # URL ê¸°ë°˜ ë¶„ì„ ì¬ì‚¬ìš©
    return await analyze_call_from_url(
        audio_url=sample_url,
        my_speaker=my_speaker,
        consultation_type=consultation_type
    )


# Create Streamable HTTP app for mounting
mcp_app = mcp.streamable_http_app()
